{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stuffed-touch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import csv\n",
    "import random\n",
    "import glob\n",
    "import subprocess\n",
    "import os\n",
    "path = '../cynet'\n",
    "sys.path.append(path)\n",
    "from cynet import cynet as cn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "assert os.path.isdir('models'), \"Make sure complete_notebook.ipynb is run first\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stone-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pertub_file(file,newfile,theta=0.1,negative=False):\n",
    "    '''\n",
    "    Takes a split file, which is typically only one row with many columns. \n",
    "    If we are doing a positive perturbation, we take all the zero events \n",
    "    in the file and with a probability, theta, change them into positive \n",
    "    events. If negative perturbation, change positive events into zeros.\n",
    "    Inputs:\n",
    "        file(str)- name of the original split file\n",
    "        newfile(str)- name of the new file to be written out.\n",
    "        theta(float)- probability of zero events being converted to 1's.\n",
    "        negative\n",
    "    '''\n",
    "    with open(file) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter= ' ')\n",
    "        with open(newfile,'w') as newcsvfile:\n",
    "            writer = csv.writer(newcsvfile, delimiter= ' ')\n",
    "\n",
    "            if negative:\n",
    "                for row in reader:\n",
    "                    for n in range(len(row)):\n",
    "                        if int(row[n]) > 0:\n",
    "                            if random.uniform(0,1) < theta:\n",
    "                                row[n] = 0\n",
    "                    writer.writerow(row)\n",
    "            else:\n",
    "                for row in reader:\n",
    "                    for n in range(len(row)):\n",
    "                        if row[n] == '0':\n",
    "                            if random.uniform(0,1) < theta:\n",
    "                                row[n] = 1\n",
    "                    writer.writerow(row)\n",
    "\n",
    "\n",
    "def alter_splitfiles(globpath, new_dir, theta=0.1,negative=False):\n",
    "    '''\n",
    "    Takes all split files that matches the glob path and outputs the pertubed\n",
    "    version of those files into a new directory.\n",
    "    Inputs:\n",
    "        globpath(str)- path to all split files.\n",
    "        new_dir(str)- directory to send files to.\n",
    "        theta(float)- probability of zero events being converted to 1's.\n",
    "        negative(bool)- Whether to do a negative perturbation.\n",
    "    '''\n",
    "    split_files = glob.glob(globpath)\n",
    "    for file in split_files:\n",
    "        newfile_name = new_dir + file.split('/')[-1]\n",
    "        pertub_file(file, newfile_name, theta=theta, negative=negative)\n",
    "\n",
    "def getEventFreq(filename, threshold):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df[df['predictions'] == 1]\n",
    "    return df\n",
    "\n",
    "def getChange(logfile, logfileP, threshold):\n",
    "    '''\n",
    "    Compare the two logfiles. Baseline log files\n",
    "    and perturbed log files.\n",
    "    '''\n",
    "\n",
    "    nE = getEventFreq(logfile, threshold).index.size\n",
    "    nEP = getEventFreq(logfileP, threshold).index.size\n",
    "    if nE == nEP:\n",
    "        return 0.0\n",
    "    if (nE == 0) and (nEP > 0):\n",
    "        nE = 1\n",
    "\n",
    "    return (nEP-nE)/(nE+0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rough-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline parameters\n",
    "var1 = 'Armed_Assault-Assassination-Hijacking-Hostage_Taking_Barricade_Incident-Hostage_Taking_Kidnapping'\n",
    "var2 = 'Bombing_Explosion-Facility_Infrastructure_Attack'\n",
    "master_folder = \"./perturbtion_temp\"\n",
    "models_folder = \"models\"\n",
    "split_path = \"./split\"\n",
    "baseline_dir = 'models'\n",
    "targets = [var1, var2]\n",
    "var_dic = {var1: 'v1',var2:'v2'}\n",
    "\n",
    "percentages = [-0.10, 0.10]\n",
    "result = {t: pd.DataFrame() for t in targets}\n",
    "model_nums = [20]\n",
    "MODEL_GLOB = f'models/*model.json'\n",
    "horizon = 7\n",
    "RUNLEN = 1827\n",
    "FLEX_TAIL_LEN = 366\n",
    "threshold = 0.85\n",
    "suffix = \"2012-01-01_2016-12-31_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "substantial-taiwan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   48.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Pairs found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   32.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   46.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Pairs found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   32.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   47.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Pairs found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   33.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   48.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Pairs found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   32.6s finished\n"
     ]
    }
   ],
   "source": [
    "subprocess.call('cp -r {} {}'.format(models_folder, master_folder), shell=True)\n",
    "new_model_folder = os.path.join(master_folder, MODEL_GLOB)\n",
    "for p1 in percentages:\n",
    "    log_dir = master_folder+'/logs/'\n",
    "    if not os.path.isdir(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "    for p2 in percentages:\n",
    "        neg1 = p1 < 0.0\n",
    "        neg2 = p2 < 0.0\n",
    "        # New directory name.\n",
    "        new_dir = '{}/split/'.format(master_folder)\n",
    "        if not os.path.isdir(new_dir):\n",
    "            os.mkdir(new_dir)\n",
    "        # Copy over the split files. Might not be necessary (if there are only two variables)\n",
    "        subprocess.call('cp {}/* {}'.format(split_path,new_dir), shell=True)\n",
    "\n",
    "        # Alter the split files. Overwrites the ones that are copied over.\n",
    "        alter_splitfiles(\"{}/*{}\".format(split_path,var1),\\\n",
    "            new_dir, theta=abs(p1),negative=neg1)\n",
    "        # Alter the split files.\n",
    "        alter_splitfiles(\"{}/*{}\".format(split_path,var2),\\\n",
    "            new_dir, theta=abs(p2),negative=neg2)\n",
    "        cn.run_pipeline(\n",
    "            os.path.join(master_folder, MODEL_GLOB),\n",
    "            model_nums, \n",
    "            horizon, \n",
    "            new_dir +'/' + suffix, \n",
    "            RUNLEN, \n",
    "            ['ALL'], \n",
    "            new_model_folder, \n",
    "            FLEX_TAIL_LEN=FLEX_TAIL_LEN,\n",
    "            cores=1,\n",
    "            gamma=True)\n",
    "\n",
    "        # Move the new log files.\n",
    "        subprocess.call('mv ./perturbtion_temp/models/*.log {}'.format(log_dir), shell=True)\n",
    "        # Get rid of intermediate files\n",
    "        subprocess.call('rm ./perturbtion_temp/models/*model_sel*', shell=True)\n",
    "        subprocess.call('rm ./perturbtion_temp/models/*.res', shell=True)\n",
    "\n",
    "        cn.peturbation_parallel(\n",
    "            'models/',\n",
    "            log_dir,\n",
    "            f'*{model_nums[0]}models#ALL.log',\n",
    "            tpr_threshold=threshold,\n",
    "            fpr_threshold=None,\n",
    "            FLEX_TAIL_LEN=FLEX_TAIL_LEN, \n",
    "            cores=1)\n",
    "\n",
    "        # Glob path for baseline glob. For matching.\n",
    "        for VAR in targets:\n",
    "\n",
    "            glob_string = '*ALL#' + VAR + '.csv'\n",
    "            baseline_glob = baseline_dir +\"/\"+ glob_string\n",
    "            baseline_files = glob.glob(baseline_glob)\n",
    "\n",
    "            # Get the change of each log file pair. \n",
    "            # Accumulate in sum.\n",
    "            sum, l = 0, 0\n",
    "            for basefile in baseline_files:\n",
    "                filename = basefile.split('/')[-1]\n",
    "                perturb_file = log_dir + filename\n",
    "                change = getChange(basefile, perturb_file, threshold)\n",
    "                sum += change\n",
    "                l += 1\n",
    "                \n",
    "            # Get the average change. \n",
    "            result[VAR].loc[var1+\"_\"+str(p1), var2+\"_\"+str(p2)] = (sum/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var, data in result.items():\n",
    "    data.to_csv(f'{var}_perturb_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
